{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Write a program to get the antonyms from WordNet.**  \n",
    "What are synonyms? A synonym is a word that means the same or almost the same as a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonyms of 'evil': ['good', 'goodness', 'good']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_antonyms(word):\n",
    "    antonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                antonyms.append(lemma.antonyms()[0].name())\n",
    "    return antonyms\n",
    "\n",
    "word = \"evil\"\n",
    "antonyms = get_antonyms(word)\n",
    "print(f\"Antonyms of '{word}': {antonyms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antonyms of 'good': ['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n",
      "Antonyms of 'bad': ['good', 'goodness', 'good', 'unregretful']\n",
      "Antonyms of 'happy': ['unhappy']\n",
      "Antonyms of 'sad': ['glad']\n",
      "Antonyms of 'hungry': ['thirsty']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_antonyms(word):\n",
    "    antonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                antonyms.append(lemma.antonyms()[0].name())\n",
    "    return antonyms\n",
    "\n",
    "def get_antonyms_for_words(words):\n",
    "    antonyms_dict = {}\n",
    "    for word in words:\n",
    "        antonyms = get_antonyms(word)\n",
    "        antonyms_dict[word] = antonyms\n",
    "    return antonyms_dict\n",
    "\n",
    "input_words = [\"good\", \"bad\", \"happy\", \"sad\", \"hungry\"]\n",
    "antonyms_dict = get_antonyms_for_words(input_words)\n",
    "\n",
    "for word, antonyms in antonyms_dict.items():\n",
    "    print(f\"Antonyms of '{word}': {antonyms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a program for stemming non-English words.\n",
    "3. Write a program for lemmatizing words Using WordNet (Use all type of stemmers for the\n",
    "comparison).\n",
    "4. Write a program to differentiate stemming and lemmatizing words.\n",
    "\n",
    "The above three questions deal with the two topics: **Stemming** and **Lemmatization**\n",
    "\n",
    "Before going into the techniques themselves, we need to be familiar with a term called *Inflected Language*.  \n",
    "**Inflected Language** is a term used for a language that contain derived words. For instance, word *\"historical\"* is derived from the word *\"history\"* and hence is the derived word. There is always a common root form fo all inflected words. Further degree of inflection varies from lower to higher depending on the language. To sum up, root form of derived of inflected words are attained using stemming and lemmatization.  \n",
    "Lemmatization and Stemming, both are used to generate root form of the derived (inflected) words. However, lemma is an actual language word, wheras stem may not be an actual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Words:  ['Bonjour', 'enfants', 'expédition', \"en cours d'exécution\", 'Heureusement']\n",
      "Stemmed Words:  ['bonjour', 'enfant', 'expédit', \"en cours d'exécu\", 'heureux']\n"
     ]
    }
   ],
   "source": [
    "# 2. Write a program for stemming non-english words.\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language=\"french\")\n",
    "words = [\"Bonjour\", \"enfants\", \"expédition\", \"en cours d'exécution\", \"Heureusement\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(\"Original Words: \", words)\n",
    "print(\"Stemmed Words: \", stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed words:  ['happi', 'and', 'histor']\n",
      "Lemmatized words:  ['happiness', 'and', 'historical']\n"
     ]
    }
   ],
   "source": [
    "# 3. Write a program for lemmatizing words using WordNet (use all types of stemmers for comparison).\n",
    "\n",
    "# import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# raw = \"My name is Abhinav. I am 21 years old. I belong that cliche section of people that likes people and interacting with them, but is an introvert in most scenarios. I currently live in Bengaluru and I am doing my Masters in AI and ML from Christ Deemed to be University, historical, happiness\"\n",
    "raw = \"happiness and historical\"\n",
    "tokens = word_tokenize(raw)\n",
    "# filtered_words = [word for word in tokens if word not in string.punctuation]\n",
    "\n",
    "porter = PorterStemmer()\n",
    "stems = [porter.stem(word) for word in tokens]\n",
    "\n",
    "lemmas = [WordNetLemmatizer().lemmatize(word) for word in tokens]\n",
    "print(\"Stemmed words: \", stems)\n",
    "print(\"Lemmatized words: \", lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named entity recognition\n",
    "# entities = ne_chunk(tags)\n",
    "# print(\"Named Entities: \", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: running\n",
      "Antonyms: ['malfunction', 'idle', 'standing', 'passing', 'standing']\n",
      "Lemmatized Word: running\n",
      "Stemmed Words:\n",
      "\tPorter: run\n",
      "\tLancaster: run\n",
      "\tSnowball: run\n",
      "Lemmatized Word: running\n",
      "==================================================\n",
      "Word: easily\n",
      "Antonyms: No antonyms found\n",
      "Lemmatized Word: easily\n",
      "Stemmed Words:\n",
      "\tPorter: easili\n",
      "\tLancaster: easy\n",
      "\tSnowball: easili\n",
      "Lemmatized Word: easily\n",
      "==================================================\n",
      "Word: jumps\n",
      "Antonyms: No antonyms found\n",
      "Lemmatized Word: jump\n",
      "Stemmed Words:\n",
      "\tPorter: jump\n",
      "\tLancaster: jump\n",
      "\tSnowball: jump\n",
      "Lemmatized Word: jump\n",
      "==================================================\n",
      "Word: worse\n",
      "Antonyms: ['better', 'better', 'good', 'unregretful']\n",
      "Lemmatized Word: worse\n",
      "Stemmed Words:\n",
      "\tPorter: wors\n",
      "\tLancaster: wors\n",
      "\tSnowball: wors\n",
      "Lemmatized Word: worse\n",
      "==================================================\n",
      "Word: cars\n",
      "Antonyms: No antonyms found\n",
      "Lemmatized Word: car\n",
      "Stemmed Words:\n",
      "\tPorter: car\n",
      "\tLancaster: car\n",
      "\tSnowball: car\n",
      "Lemmatized Word: car\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "import nltk\n",
    "\n",
    "# Function to get antonyms from WordNet\n",
    "def get_antonyms(word):\n",
    "    antonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                antonyms.append(lemma.antonyms()[0].name())\n",
    "    return antonyms\n",
    "\n",
    "\n",
    "# Function for lemmatizing words using WordNet\n",
    "def lemmatize_word(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word, pos='n')\n",
    "\n",
    "# Function to differentiate stemming and lemmatizing words\n",
    "def stem_vs_lemmatize(word):\n",
    "    stemmers = {\n",
    "        \"Porter\": PorterStemmer(),\n",
    "        \"Lancaster\": LancasterStemmer(),\n",
    "        \"Snowball\": SnowballStemmer(\"english\")\n",
    "    }\n",
    "    stemmed_words = {name: stemmer.stem(word) for name, stemmer in stemmers.items()}\n",
    "    lemmatized_word = lemmatize_word(word)\n",
    "    return stemmed_words, lemmatized_word\n",
    "\n",
    "# 5 sample words for analysis and comparison\n",
    "words = [\"running\", \"easily\", \"jumps\", \"worse\", \"cars\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"Word: {word}\")\n",
    "    \n",
    "    # Antonyms\n",
    "    antonyms = get_antonyms(word)\n",
    "    print(f\"Antonyms: {antonyms if antonyms else 'No antonyms found'}\")\n",
    "    \n",
    "    \n",
    "    # Lemmatization\n",
    "    lemma_word = lemmatize_word(word)\n",
    "    print(f\"Lemmatized Word: {lemma_word}\")\n",
    "    \n",
    "    # Stemming vs Lemmatization\n",
    "    stemmed_words, lemmatized_word = stem_vs_lemmatize(word)\n",
    "    print(\"Stemmed Words:\")\n",
    "    for name, stemmed_word in stemmed_words.items():\n",
    "        print(f\"\\t{name}: {stemmed_word}\")\n",
    "    print(f\"Lemmatized Word: {lemmatized_word}\")\n",
    "    \n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
